{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Imports\n"
      ],
      "metadata": {
        "id": "F8wIPTqEAamw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FUuFMoUG-lxo",
        "outputId": "fb98f257-8848-4d99-99cb-3e51594a24ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbcf044d",
        "outputId": "1a6a2ae2-7d2d-468f-be94-9fed5bf1b807"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive') # Change this path to where your 'src' folder is located\n",
        "print(os.getcwd())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, cv2, numpy as np, matplotlib.pyplot as plt, seaborn as sns, joblib\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score, roc_curve, confusion_matrix\n",
        "\n",
        "import sys, os\n",
        "sys.path.append(os.path.abspath('/content/drive/MyDrive/Signature_Project/src'))\n",
        "from preprocess import preprocess_image\n",
        "from features import extract_features\n",
        "\n",
        "print(\"✅ Imports successful!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Q34oB_L_V6t",
        "outputId": "b6229ad5-6d14-41e8-edbc-c8539f60cbdc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Imports successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Paths"
      ],
      "metadata": {
        "id": "VgFKfj82AQ2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"/content/drive/MyDrive/Signature_Project/data/signatures\"\n",
        "GENUINE_DIR = os.path.join(DATA_DIR, \"full_forg\")\n",
        "FORGED_DIR = os.path.join(DATA_DIR, \"full_org\")"
      ],
      "metadata": {
        "id": "QXhhipQxAAWt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load images and labels"
      ],
      "metadata": {
        "id": "buFl3MchA5xI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        "    X, y = [], []\n",
        "    for path, label in [(GENUINE_DIR, 1), (FORGED_DIR, 0)]:\n",
        "        for f in os.listdir(path):\n",
        "            if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
        "                X.append(os.path.join(path, f))\n",
        "                y.append(label)\n",
        "    return X, np.array(y)\n",
        "\n",
        "image_paths, labels = load_dataset()\n",
        "print(f\"Loaded {len(image_paths)} images (genuine={sum(labels)}, forged={len(labels)-sum(labels)})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2ljYiorA1ag",
        "outputId": "3fa94fbc-628e-4ce0-cd2d-e072b213488d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2640 images (genuine=1320, forged=1320)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preprocess and extract features"
      ],
      "metadata": {
        "id": "OSvgKe9ZBzc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features = []\n",
        "for path in image_paths:\n",
        "    img = preprocess_image(path)\n",
        "    feat = extract_features(img)\n",
        "    features.append(feat)\n",
        "\n",
        "X = np.array(features)\n",
        "y = labels\n",
        "print(\"Feature matrix shape:\", X.shape)"
      ],
      "metadata": {
        "id": "RIqldMAuBeTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##train_test_split"
      ],
      "metadata": {
        "id": "MURMFwb0ClFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "FtOvkuyFCiEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Pipelines\n"
      ],
      "metadata": {
        "id": "_ACQS2xNDKq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5 — Define pipelines\n",
        "# =============================================================\n",
        "def make_pipeline(model):\n",
        "    return Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('pca', PCA(n_components=0.95)),\n",
        "        ('clf', model)\n",
        "    ])\n",
        "\n",
        "models = {\n",
        "    \"LogisticRegression\": LogisticRegression(max_iter=2000, class_weight='balanced'),\n",
        "    \"SVM\": SVC(kernel='rbf', probability=True, class_weight='balanced'),\n",
        "    \"DecisionTree\": DecisionTreeClassifier(max_depth=10, class_weight='balanced'),\n",
        "    \"SGDClassifier\": SGDClassifier(loss='log_loss', max_iter=1000, class_weight='balanced')\n",
        "}\n",
        "\n",
        "# =============================================================\n",
        "# STEP 6 — Train and evaluate\n",
        "# =============================================================\n",
        "results = {}\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "    pipe = make_pipeline(model)\n",
        "    pipe.fit(X_train, y_train)\n",
        "    y_pred = pipe.predict(X_test)\n",
        "    y_prob = pipe.predict_proba(X_test)[:,1] if hasattr(pipe, \"predict_proba\") else None\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    auc = roc_auc_score(y_test, y_prob) if y_prob is not None else None\n",
        "    print(f\"AUC: {auc:.4f}\" if auc else \"No probability output for AUC.\")\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "    plt.title(f\"{name} Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
        "    plt.show()\n",
        "\n",
        "    results[name] = {\"model\": pipe, \"AUC\": auc}\n",
        "\n",
        "# =============================================================\n",
        "# STEP 7 — Compute FAR / FRR / EER (for best model)\n",
        "# =============================================================\n",
        "best_model = max(results.items(), key=lambda kv: kv[1][\"AUC\"] if kv[1][\"AUC\"] else 0)[1][\"model\"]\n",
        "y_score = best_model.predict_proba(X_test)[:,1]\n",
        "fpr, tpr, thr = roc_curve(y_test, y_score)\n",
        "FAR = fpr\n",
        "FRR = 1 - tpr\n",
        "eer_index = np.argmin(np.abs(FAR - FRR))\n",
        "EER = (FAR[eer_index] + FRR[eer_index]) / 2\n",
        "print(f\"Equal Error Rate (EER): {EER*100:.2f}%\")\n",
        "\n",
        "plt.plot(FAR, 1-FRR, label='ROC')\n",
        "plt.xlabel('False Acceptance Rate')\n",
        "plt.ylabel('True Acceptance Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# =============================================================\n",
        "# STEP 8 — Save model\n",
        "# =============================================================\n",
        "os.makedirs(\"../models\", exist_ok=True)\n",
        "joblib.dump(best_model, \"../models/best_signature_model.joblib\")\n",
        "print(\"✅ Model saved at ../models/best_signature_model.joblib\")\n"
      ],
      "metadata": {
        "id": "vJlS3p_2DSoK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}